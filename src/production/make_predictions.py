"""
Script de prÃ©diction de points de fuite Ã  partir de vidÃ©os de conduite.

Utilise l'analyse de flux optique avec segmentation vÃ©hicule optionnelle.
Deux mÃ©thodes disponibles : 'flow' (sÃ©paration directe) et 'colinearity' (optimisation).


Configuration via config.json dans le mÃªme dossier.
"""

import cv2
import numpy as np
import os
import json
import mlx.core as mx
from typing import Optional, Dict, Any, List
from pathlib import Path
import gc
import time

from src.core.flow import calculate_flow, find_separation_points
from src.utilities.pixel_angle_converter import pixels_to_angles
from src.core.segmentation import VehicleDetector
from src.core.optimizers import AdamOptimizer
from src.utilities.paths import get_labeled_dir, get_pred_dir, get_masks_dir, ensure_dir_exists
from src.utilities.project_constants import get_project_constants
from src.utilities.fix_predictions import fix_predictions
from src.core.flow_filter import FlowFilterSample


def load_config(config_path: Optional[str] = None) -> Dict[str, Any]:
    """Charge la configuration depuis config.json."""
    if config_path is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        config_path = os.path.join(script_dir, 'config.json')
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    return {
        'prediction_method': config.get('prediction_method', 'colinearity'),
        'use_segmentation': config.get('use_segmentation', True),
        'filter_config': config.get('filter_config', None),
        'optimizer_config': config.get('optimizer_config', None)
    }


class VideoProcessor:
    """
    Processeur vidÃ©o pour prÃ©diction de points de fuite.
    
    GÃ¨re le traitement complet d'une vidÃ©o avec flux optique,
    segmentation vÃ©hicule optionnelle et estimation du point de fuite.
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.detector = None
        self.manual_mask = None
        self.prev_vehicle_mask = None
        self.prev_gray = None
        self.frame_count = 0
        self.total_frames = 0
        self.results = []
        
        # Initialisation filtre et optimiseur avec configs
        filter_config = config.get('filter_config')
        if filter_config:
            self.filter = FlowFilterSample(filter_config)
        else:
            self.filter = FlowFilterSample()  # Utilise config par dÃ©faut
        
        optimizer_config = config.get('optimizer_config')
        if optimizer_config:
            self.optimizer = AdamOptimizer(**optimizer_config)
        else:
            self.optimizer = AdamOptimizer()  # Utilise config par dÃ©faut

    def process_video(
        self, 
        video_index: int,
        run_name: str = "default"
    ) -> bool:
        """
        Traite une vidÃ©o complÃ¨te et sauvegarde les prÃ©dictions.
        
        Args:
            video_index: Index de la vidÃ©o 
            run_name: Nom du run d'expÃ©rimentation
            
        Returns:
            True si succÃ¨s, False sinon
        """
        # Create video path
        video_path = get_labeled_dir() / f"{video_index}.hevc"
        if not os.path.exists(video_path):
            print(f"âš ï¸  VidÃ©o {video_index} introuvable")
            return False

        # PrÃ©paration dossiers de sortie
        pred_run_dir = self._prepare_output_directories(run_name)
        
        # Initialisation
        cap = self._initialize_video(str(video_path))
        if cap is None:
            return False
        
        self._setup_processing_components(str(video_path))
        
        # PremiÃ¨re frame
        first_frame = self._process_first_frame(cap)
        if first_frame is None:
            cap.release()
            return False
        
        # Traitement de toutes les frames
        self._process_all_frames(cap)
        
        # Nettoyage
        cap.release()
        gc.collect()
        
        # Sauvegarde prÃ©dictions
        self._save_predictions(pred_run_dir, video_index)
        
        print(f"\nâœ… VidÃ©o {video_index} terminÃ©e: {len(self.results)} frames")
        return True

    def _prepare_output_directories(self, run_name: str) -> Path:
        """PrÃ©pare les dossiers de sortie et sauvegarde la configuration."""
        pred_run_dir = ensure_dir_exists(get_pred_dir(run_name))
        
        # Sauvegarde configuration
        config_file = pred_run_dir / "config.json"
        self._save_config(config_file, run_name)
        
        return pred_run_dir

    def _save_config(self, config_file: Path, run_name: str) -> None:
        """Sauvegarde la configuration du run."""
        config_to_save = {
            "run_name": run_name,
            "config": self.config,
            "description": f"Make predictions - mÃ©thode {self.config['prediction_method']}",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        with open(config_file, 'w') as f:
            json.dump(config_to_save, f, indent=2)

    def _save_predictions(self, pred_run_dir: Path, video_index: int) -> None:
        """Sauvegarde les prÃ©dictions dans le dossier du run."""
        output_file = pred_run_dir / f"{video_index}.txt"
        
        with open(output_file, 'w') as f:
            for yaw, pitch in self.results:
                f.write(f"{yaw:.6f} {pitch:.6f}\n")
        
        print(f"ğŸ’¾ PrÃ©dictions: {output_file}")

    def _initialize_video(self, video_path: str) -> Optional[cv2.VideoCapture]:
        """Initialise la capture vidÃ©o et compte les frames."""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print("âŒ Impossible d'ouvrir la vidÃ©o")
            return None
        
        self.total_frames, cap = self._get_video_frame_count(cap, video_path)
        return cap
    
    def _get_video_frame_count(self, cap: cv2.VideoCapture, video_path: str) -> tuple:
        """Compte le nombre rÃ©el de frames dans la vidÃ©o."""
        current_pos = cap.get(cv2.CAP_PROP_POS_FRAMES)
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        
        frame_count = 0
        max_frames = 2000
        while frame_count < max_frames:
            ret, _ = cap.read()
            if not ret:
                break
            frame_count += 1
        
        print(f"ğŸ“Š Total frames: {frame_count}")
        
        cap.release()
        cap = cv2.VideoCapture(video_path)
        cap.set(cv2.CAP_PROP_POS_FRAMES, current_pos)
        
        return frame_count, cap

    def _setup_processing_components(self, video_path: str) -> None:
        """Configure les composants de traitement."""
        frame_width = get_project_constants()["frame_width"]
        frame_height = get_project_constants()["frame_height"]
        
        # Initialisation segmentation si activÃ©e
        if self.config['use_segmentation']:
            self.detector = VehicleDetector()
            self.manual_mask = np.zeros((frame_height, frame_width), dtype=np.uint8)
            self.prev_vehicle_mask = np.zeros((frame_height, frame_width), dtype=np.uint8)
            
            # Chargement masque manuel
            self._load_manual_mask(video_path)

    def _load_manual_mask(self, video_path: str) -> None:
        """Charge le masque manuel si disponible."""
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        mask_path = get_masks_dir() / f"{video_name}_mask.png"
        
        if os.path.exists(mask_path):
            print(f"ğŸ“‚ Masque chargÃ©: {mask_path}")
            self.manual_mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)
        else:
            print("ğŸ“‚ Pas de masque manuel trouvÃ©")

    def _process_first_frame(self, cap: cv2.VideoCapture) -> Optional[np.ndarray]:
        """Traite la premiÃ¨re frame et initialise prev_gray."""
        ret, frame = cap.read()
        if not ret:
            print("âŒ Impossible de lire la premiÃ¨re frame")
            return None
        
        self.prev_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        return frame

    def _process_all_frames(self, cap: cv2.VideoCapture) -> None:
        """Traite toutes les frames de la vidÃ©o."""
        while True:
            # Affichage progression
            progress = (self.frame_count / (self.total_frames - 1)) * 100
            print(f"\rProgression: {progress:.1f}%", end="", flush=True)
            
            ret, frame = cap.read()
            if not ret:
                break
            
            self.frame_count += 1
            self._process_single_frame(frame)

    def _process_single_frame(self, frame: np.ndarray) -> None:
        """Traite une frame individuelle."""
        # Conversion grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        # Gestion masques
        combined_mask = self._create_mask(frame)
        # Calcul flux optique et filtrage
        flow, _, _ = calculate_flow(self.prev_gray, gray, combined_mask)
        flow, weights = self.filter.filter_and_weight(flow)
        
        # PrÃ©diction selon mÃ©thode choisie
        x, y = self._predict_vanishing_point(flow, combined_mask, weights)
        
        # Conversion angles et stockage
        yaw, pitch = pixels_to_angles(x, y)
        self._store_result(x, y, yaw, pitch)
        
        # Mise Ã  jour Ã©tat
        self.prev_gray = gray

    def _create_mask(self, frame: np.ndarray) -> np.ndarray:
        """dÃ©tecte les vÃ©hicules sur la frame, crÃ©e le masque correspondant 
        dilate le masque 
        combine avec le masque du capot et le masque de la frame prÃ©cÃ©dente.
        """
        if not self.config['use_segmentation']:
            return np.zeros_like(self.prev_gray)
        
        current_vehicle_mask = self.detector.detect_vehicles(frame)
        current_vehicle_mask = self.detector.dilate_mask(current_vehicle_mask)
        combined_mask = self.detector.combine_masks(
            self.manual_mask, 
            current_vehicle_mask, 
            self.prev_vehicle_mask
        )
        self.prev_vehicle_mask = current_vehicle_mask
        return combined_mask

    def _predict_vanishing_point(self, flow: np.ndarray, mask: np.ndarray, weights: np.ndarray) -> tuple:
        """PrÃ©dit le point de fuite selon la mÃ©thode configurÃ©e."""
        if self.config['prediction_method'] == "flow":
            return find_separation_points(flow, mask)
        elif self.config['prediction_method'] == "colinearity":
            vanishing_point = self.optimizer.optimize_single(flow, weights=weights)
            return map(int, vanishing_point) # cleaner than converting to int element by element
        else:
            raise ValueError(f"MÃ©thode inconnue: {self.config['prediction_method']}")

    def _store_result(self, x: int, y: int, yaw: float, pitch: float) -> None:
        """Stocke le rÃ©sultat de prÃ©diction."""
        self.results.append([yaw, pitch])



def main(
    video_indices: Optional[List[int]] = None,
    run_name: str = "default"
) -> None:
    """
    Traite les vidÃ©os pour prÃ©diction de points de fuite.
    
    Args:
        video_indices: Indices des vidÃ©os Ã  traiter (dÃ©faut: toutes)
        run_name: Nom du run d'expÃ©rimentation
    """
    if video_indices is None:
        video_indices = list(range(5))

    # Configuration
    config = load_config()
    
    print(f"ğŸš€ DÃ‰MARRAGE RUN: {run_name}")
    print(f"ğŸ“‚ PrÃ©dictions: {get_pred_dir(run_name)}")
    print(f"ğŸ¯ VidÃ©os: {video_indices}")
    print(f"âš™ï¸  MÃ©thode: {config['prediction_method']}")
    
    # Traitement vidÃ©os
    success_count = 0
    for video_index in video_indices:
        print(f"\nğŸ¬ Traitement vidÃ©o {video_index} - Run: {run_name}")
        # Traitement
        processor = VideoProcessor(config)
        success = processor.process_video(video_index, run_name)
        if success:
            success_count += 1

    print(f"\nğŸ RUN '{run_name}' TERMINÃ‰: {success_count}/{len(video_indices)} vidÃ©os rÃ©ussies")


if __name__ == "__main__":
    main() 