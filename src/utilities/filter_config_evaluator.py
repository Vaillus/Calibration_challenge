#!/usr/bin/env python3
"""
üéØ FILTER CONFIG EVALUATOR

√âvaluateur de configurations de filtrage sigmo√Øde.
Charge les donn√©es et √©value les performances d'une configuration donn√©e.
"""

import time
import numpy as np
import mlx.core as mx
from pathlib import Path
from typing import Union, List, Tuple, Optional, Dict, Any
import gc
from dataclasses import dataclass

from src.utilities.paths import get_pred_dir, get_means_dir, get_intermediate_dir
from src.utilities.load_flows import load_flows
from src.utilities.ground_truth import read_ground_truth_pixels
from src.core.flow_filter import FlowFilterBatch
from src.core.optimizers import AdamOptimizer
from src.utilities.pixel_angle_converter import angles_to_pixels


@dataclass
class FrameBatch:
    """Donn√©es charg√©es pour un batch de frames - structure immutable"""
    flows: mx.array                        # (batch_size, h, w, 2)
    labels: mx.array                       # (batch_size, 2) 
    baseline_predictions: mx.array         # (batch_size, 2)
    baseline_distances: mx.array           # (batch_size,)
    mean_points: Optional[mx.array]        # (batch_size, 2) ou None
    frame_metadata: List[Tuple[int, int]]  # [(video_id, frame_id), ...]


class DataLoader:
    """Chargement optimis√© de donn√©es pour les benchmarks de filtrage"""
    
    def __init__(self, run_name: str = "5", verbose: bool = True):
        """
        Args:
            baseline_pred_gen: G√©n√©ration de pr√©dictions baseline
            verbose: Affichage des messages de progression
        """
        self.run_name = run_name
        self.verbose = verbose
        
        # Paths
        self.baseline_pred_dir = get_pred_dir(run_name)
        self.means_dir = get_means_dir(run_name)
    
    def load_frame_batch(self, data_source: Union[int, List[Tuple[int, int]], str]) -> FrameBatch:
        """
        Point d'entr√©e principal - charge toutes les donn√©es pour un batch de frames.
        
        Args:
            data_source: 
                - int: video_id pour toute la vid√©o
                - [(video_id, frame_id), ...]: batch custom
                - 'all': toutes les vid√©os disponibles
                
        Returns:
            FrameBatch: Toutes les donn√©es charg√©es et pr√™tes √† utiliser
        """
        # 1. D√©terminer les frames √† charger
        frame_list = self._resolve_frame_list(data_source)
        # 2. Extraire les video_ids uniques
        video_ids = self._get_unique_video_ids(frame_list)
        if self.verbose:
            video_ids_sorted = sorted(video_ids)
            print(f"üìÇ Chargement de {len(frame_list)} frames depuis les vid√©os {video_ids_sorted}...")
        
        # 3. Charger toutes les donn√©es
        flows = self._load_flows(frame_list, video_ids)
        labels = self._load_labels(frame_list, video_ids)
        baseline_preds = self._load_baseline(frame_list, video_ids)
        mean_points = self._load_mean_points(frame_list, video_ids)
        
        # 4. Calculer distances baseline
        baseline_distances = mx.sqrt(
            mx.sum(mx.square(baseline_preds - labels), axis=1)
        )
        mx.eval(baseline_distances)
        
        if self.verbose:
            print(f"‚úÖ Donn√©es charg√©es: flows{flows.shape}, labels{labels.shape}")
        
        return FrameBatch(
            flows=flows,
            labels=labels,
            baseline_predictions=baseline_preds,
            baseline_distances=baseline_distances,
            mean_points=mean_points,
            frame_metadata=frame_list
        )
    
    def _resolve_frame_list(
            self, 
            data_source: Union[int, List[Tuple[int, int]], str]
        ) -> List[Tuple[int, int]]:
        """
        D√©termine la liste des frames √† charger selon data_source.
        Extrait de la logique actuelle de _determine_frame_list_and_group.
        """
        if isinstance(data_source, int):
            # Une vid√©o compl√®te
            video_id = data_source
            gt_pixels = read_ground_truth_pixels(video_id)
            num_frames = len(gt_pixels) - 1
            return [(video_id, i) for i in range(num_frames)]
                
        elif isinstance(data_source, list):
            # Batch custom
            return data_source
                
        elif data_source == 'all':
            # Toutes les vid√©os
            frame_list = []
            for video_id in range(5):  # Vid√©os 0-4
                try:
                    gt_pixels = read_ground_truth_pixels(video_id)
                    num_frames = len(gt_pixels)
                    frame_list.extend([(video_id, i) for i in range(num_frames)])
                except Exception as e:
                    if self.verbose:
                        print(f"‚ö†Ô∏è Erreur vid√©o {video_id}: {e}")
            return frame_list
                        
        else:
            raise ValueError(f"data_source non support√©: {data_source}")
    
    def _get_unique_video_ids(self, frame_list: List[Tuple[int, int]]) -> set[int]:
        """
        Extrait les video_ids uniques d'une liste de frames.
        
        Args:
            frame_list: Liste des (video_id, frame_id)
            
        Returns:
            Set[int]: Ensemble des video_ids uniques
        """
        return set(video_id for video_id, _ in frame_list)
    
    def _load_flows(
        self, 
        frame_list: List[Tuple[int, int]], 
        video_ids: set[int]
    ) -> mx.array:
        """Charge flows group√©s par vid√©o (logique extraite de _load_flows_by_video)."""
        # Charger chaque vid√©o une seule fois
        flows_dict = {}
        for video_id in video_ids:
            flows = load_flows(video_id, return_mlx=False, verbose=False)
            if flows is None:
                raise ValueError(f"Impossible de charger flows pour vid√©o {video_id}")
            flows_dict[video_id] = flows
        
        # Extraire les frames dans l'ordre de frame_list
        flows_list = []
        for video_id, frame_id in frame_list:
            if frame_id >= len(flows_dict[video_id]):
                raise ValueError(f"Frame {frame_id} non disponible pour vid√©o {video_id}")
            flows_list.append(flows_dict[video_id][frame_id-1]) # frame_id-1 
            # car les frames sont index√©es √† partir de 1 dans le dossier de flows
        
        # Convertir en batch MLX
        flows_np = np.stack(flows_list, axis=0)
        flows_mlx = mx.array(flows_np, dtype=mx.float32)
        mx.eval(flows_mlx)
        
        # Lib√©rer m√©moire
        del flows_dict, flows_list, flows_np
        gc.collect()
        
        return flows_mlx
    
    def _load_labels(
            self, 
            frame_list: List[Tuple[int, int]], 
            video_ids: set[int]
        ) -> mx.array:
        """Charge labels group√©s par vid√©o (logique extraite de _load_labels_by_video)."""
        # Charger chaque vid√©o une seule fois
        labels_dict = {}
        for video_id in video_ids:
            gt_pixels = read_ground_truth_pixels(video_id)  # D√©j√† en pixels !
            labels_dict[video_id] = gt_pixels
        
        # Extraire dans l'ordre
        labels_list = []
        for video_id, frame_id in frame_list:
            if frame_id >= len(labels_dict[video_id]):
                raise ValueError(f"Label {frame_id} non disponible pour vid√©o {video_id}")
            
            x, y = labels_dict[video_id][frame_id]
            labels_list.append([x, y])
        
        labels_np = np.array(labels_list, dtype=np.float32)
        labels_mlx = mx.array(labels_np, dtype=mx.float32)
        mx.eval(labels_mlx)
        
        # Lib√©rer m√©moire
        del labels_dict, labels_list, labels_np
        gc.collect()
        
        return labels_mlx
    
    def _load_baseline(self, frame_list: List[Tuple[int, int]], video_ids: set[int]) -> mx.array:
        """Charge baseline group√© par vid√©o (logique extraite de _load_baseline_by_video)."""
        if not self.baseline_pred_dir.exists():
            raise ValueError(f"Dossier baseline non trouv√©: {self.baseline_pred_dir}")
        
        # Charger chaque fichier de pr√©dictions une seule fois
        baseline_dict = {}
        for video_id in video_ids:
            pred_file = self.baseline_pred_dir / f"{video_id}.txt"
            
            if not pred_file.exists():
                raise ValueError(f"Pr√©dictions baseline non trouv√©es: {pred_file}")
            
            baseline_preds_angles = np.loadtxt(pred_file)
            # Convertir les pr√©dictions baseline (angles) en pixels
            baseline_preds = np.zeros((len(baseline_preds_angles), 2), dtype=np.float32)
            for i, pred in enumerate(baseline_preds_angles):
                pitch, yaw = pred[0], pred[1]  # pred est [pitch, yaw] en radians
                x, y = angles_to_pixels(pitch, yaw)
                baseline_preds[i] = [x, y]
            
            baseline_dict[video_id] = baseline_preds
        
        # Extraire dans l'ordre
        predictions_list = []
        for video_id, frame_id in frame_list:
            if frame_id >= len(baseline_dict[video_id]):
                raise ValueError(f"Pr√©diction baseline {frame_id} non disponible pour vid√©o {video_id}")
            
            predictions_list.append(baseline_dict[video_id][frame_id])
        
        predictions_np = np.array(predictions_list, dtype=np.float32)
        baseline_mlx = mx.array(predictions_np, dtype=mx.float32)
        mx.eval(baseline_mlx)
        
        # Lib√©rer m√©moire
        del baseline_dict, predictions_list, predictions_np
        gc.collect()
        
        return baseline_mlx
    
    def _load_mean_points(self, frame_list: List[Tuple[int, int]], video_ids: set[int]) -> Optional[mx.array]:
        """Charge les points moyens group√©s par vid√©o (logique extraite de _load_mean_points_by_video)."""
        if not self.means_dir.exists():
            return None
        
        # Charger chaque fichier de points moyens une seule fois
        mean_points_dict = {}
        for video_id in video_ids:
            mean_file = self.means_dir / f"{video_id}.txt"
            
            if not mean_file.exists():
                mean_points_dict[video_id] = None
                continue
            
            try:
                # Charger le point moyen (x, y)
                with open(mean_file, 'r') as f:
                    line = f.readline().strip()
                    x, y = map(float, line.split())
                    mean_points_dict[video_id] = (x, y)
            except Exception as e:
                if self.verbose:
                    print(f"‚ö†Ô∏è Erreur points moyens vid√©o {video_id}: {e}")
                mean_points_dict[video_id] = None
        
        # Construire la liste des points moyens dans l'ordre des frames
        mean_points_list = []
        has_valid_points = False
        
        for video_id, frame_id in frame_list:
            if video_id in mean_points_dict and mean_points_dict[video_id] is not None:
                mean_points_list.append(list(mean_points_dict[video_id]))
                has_valid_points = True
            else:
                # Utiliser le centre d'image par d√©faut (sera calcul√© dynamiquement)
                mean_points_list.append([0.0, 0.0])  # Placeholder
        
        if has_valid_points:
            mean_points_np = np.array(mean_points_list, dtype=np.float32)
            mean_points_mlx = mx.array(mean_points_np, dtype=mx.float32)
            mx.eval(mean_points_mlx)
            
            # Lib√©rer m√©moire
            del mean_points_dict, mean_points_list, mean_points_np
            gc.collect()
            
            return mean_points_mlx
        else:
            return None


class FilterConfigEvaluator:
    """
    √âvaluateur de configurations de filtrage sigmo√Øde.
    Charge les donn√©es et √©value les performances d'une configuration donn√©e.
    
    Modes de donn√©es :
    - video_id (int) : toutes les frames d'une vid√©o
    - [(video_id, frame_id), ...] : batch custom  
    - 'all' : toutes les vid√©os disponibles (0-4)
    """
    
    def __init__(self, data_source: Union[int, List[Tuple[int, int]], str], 
                 baseline_pred_gen: str = "5", verbose: bool = True):
        """
        Args:
            data_source: 
                - int: video_id pour toute la vid√©o
                - [(video_id, frame_id), ...]: batch custom
                - 'all': toutes les vid√©os disponibles
            baseline_pred_gen: G√©n√©ration de pr√©dictions baseline (default: 5)
            verbose: Affichage des messages
        """
        self.data_source = data_source
        self.baseline_pred_gen = baseline_pred_gen
        self.verbose = verbose
        
        # Donn√©es charg√©es (sera un FrameBatch apr√®s load_data)
        self.data_batch: Optional[FrameBatch] = None
        
    def load_data(self):
        """
        Charge toutes les donn√©es via le DataLoader.
        """
        loader = DataLoader(self.baseline_pred_gen, self.verbose)
        self.data_batch = loader.load_frame_batch(self.data_source)
    
    @property
    def flows_data(self) -> mx.array:
        """Acc√®s aux flows (compatibilit√© avec l'ancienne interface)"""
        if self.data_batch is None:
            raise ValueError("Donn√©es non charg√©es. Appelez load_data() d'abord.")
        return self.data_batch.flows
    
    @property 
    def labels_data(self) -> mx.array:
        """Acc√®s aux labels (compatibilit√© avec l'ancienne interface)"""
        if self.data_batch is None:
            raise ValueError("Donn√©es non charg√©es. Appelez load_data() d'abord.")
        return self.data_batch.labels
    
    @property
    def baseline_predictions(self) -> mx.array:
        """Acc√®s aux pr√©dictions baseline (compatibilit√© avec l'ancienne interface)"""
        if self.data_batch is None:
            raise ValueError("Donn√©es non charg√©es. Appelez load_data() d'abord.")
        return self.data_batch.baseline_predictions
    
    @property
    def baseline_distances(self) -> mx.array:
        """Acc√®s aux distances baseline (compatibilit√© avec l'ancienne interface)"""
        if self.data_batch is None:
            raise ValueError("Donn√©es non charg√©es. Appelez load_data() d'abord.")
        return self.data_batch.baseline_distances
    
    @property
    def mean_points_data(self) -> Optional[mx.array]:
        """Acc√®s aux points moyens (compatibilit√© avec l'ancienne interface)"""
        if self.data_batch is None:
            raise ValueError("Donn√©es non charg√©es. Appelez load_data() d'abord.")
        return self.data_batch.mean_points
    
    @property
    def frame_list(self) -> List[Tuple[int, int]]:
        """Acc√®s √† la liste des frames (compatibilit√© avec l'ancienne interface)"""
        if self.data_batch is None:
            raise ValueError("Donn√©es non charg√©es. Appelez load_data() d'abord.")
        return self.data_batch.frame_metadata

    def predict_from_config(self, 
                           filter_config: dict,
                           use_mean_points: bool = False,
                           adam_config: dict = None) -> mx.array:
        """
        Pr√©dit les points de fuite pour une configuration de filtre donn√©e.
        
        Args:
            filter_config: Configuration du filtre avec structure FlowFilter
            use_mean_points: Utiliser les points moyens pour la colin√©arit√© (False = centre image)
            adam_config: Configuration Adam (utilise les param√®tres par d√©faut si None)
            
        Returns:
            mx.array: Pr√©dictions optimis√©es de forme (batch_size, 2)
        """
        if self.flows_data is None:
            raise ValueError("Donn√©es non charg√©es. Appelez load_data() d'abord.")
        
        # 1. Pr√©parer les points de r√©f√©rence pour la colin√©arit√©
        reference_points = None
        if use_mean_points and self.mean_points_data is not None:
            reference_points = self.mean_points_data
        
        # 2. Cr√©er le filtre et calculer les poids
        flow_filter = FlowFilterBatch(filter_config)
        weights = flow_filter.compute_weights(self.flows_data, reference_points=reference_points)
        mx.eval(weights)
        
        # 3. Configuration et lancement de l'optimiseur Adam
        adam_optimizer = AdamOptimizer()
        if adam_config:
            adam_optimizer = AdamOptimizer(**adam_config)
        
        # Points de d√©part au centre de l'image
        batch_size = self.flows_data.shape[0]
        h, w = self.flows_data.shape[1], self.flows_data.shape[2]
        center_points = mx.tile(mx.array([w // 2, h // 2], dtype=mx.float32), (batch_size, 1))
        mx.eval(center_points)
        
        # 4. Optimisation batch
        predictions = adam_optimizer.optimize_batch(
            self.flows_data,
            starting_points=center_points,
            weights_batch=weights
        )
        mx.eval(predictions)
        
        return predictions

    def evaluate_filter_config(self, 
                              filter_config: dict,
                              use_mean_points: bool = False,
                              adam_config: dict = None,
                              verbose: bool = None) -> float:
        """
        √âvalue une configuration de filtre et retourne la distance moyenne.
        
        Args:
            filter_config: Configuration du filtre avec structure FlowFilter
            use_mean_points: Utiliser les points moyens pour la colin√©arit√© (False = centre image)
            adam_config: Configuration Adam (utilise les param√®tres par d√©faut si None)
            verbose: Afficher les d√©tails (None = utilise self.verbose)
            
        Returns:
            float: Distance moyenne entre pr√©dictions et labels
        """
        # Utiliser predict_from_config pour obtenir les pr√©dictions
        predictions = self.predict_from_config(filter_config, use_mean_points, adam_config)
        
        # Calculer les distances
        distances = self.compute_distances(predictions)
        mean_distance = float(mx.mean(distances))
        
        # Affichage optionnel des d√©tails
        show_verbose = verbose if verbose is not None else self.verbose
        if show_verbose:
            print(f"üéØ Config: norm={'‚úì' if filter_config.get('norm', {}).get('is_used', False) else '‚úó'}, "
                  f"colin={'‚úì' if filter_config.get('colinearity', {}).get('is_used', False) else '‚úó'}, "
                  f"heatmap={'‚úì' if filter_config.get('heatmap', {}).get('is_used', False) else '‚úó'}")
            print(f"   Distance moyenne: {mean_distance:.2f}")
        
        return mean_distance

    def compute_distances(self, predictions: mx.array) -> mx.array:
        """
        Calcule les distances euclidiennes entre pr√©dictions et labels.
        
        Args:
            predictions: Pr√©dictions de forme (batch_size, 2)
            
        Returns:
            mx.array: Distances de forme (batch_size,)
        """
        if self.labels_data is None:
            raise ValueError("Labels non charg√©s. Appelez load_data() d'abord.")
        
        distances = mx.sqrt(
            mx.sum(mx.square(predictions - self.labels_data), axis=1)
        )
        mx.eval(distances)
        return distances

    def _print_config(self, config: dict, use_mean_points: bool = None, indent: str = ""):
        """Affiche une configuration de mani√®re lisible."""
        norm = config['norm']
        colin = config['colinearity']
        heatmap = config.get('heatmap', {})
        
        config_str = f"{indent}norm(k={norm['k']:.2f}, x0={norm['x0']:.2f}), "
        config_str += f"colin(k={colin['k']:.2f}, x0={colin['x0']:.4f})"
        
        if heatmap.get('is_used', False):
            config_str += f", heatmap(w={heatmap.get('weight', 0.0):.2f})"
        
        if use_mean_points is not None:
            config_str += f", mean_pts={'‚úì' if use_mean_points else '‚úó'}"
        
        print(config_str)
    
    def _print_config_compact(self, config: dict, use_mean_points: bool = None):
        """Affiche une configuration de mani√®re compacte."""
        norm = config['norm']
        colin = config['colinearity']
        heatmap = config.get('heatmap', {})
        
        config_str = f"   Config: N(k={norm['k']:.2f},x0={norm['x0']:.2f}) "
        config_str += f"C(k={colin['k']:.2f},x0={colin['x0']:.4f})"
        
        if heatmap.get('is_used', False):
            config_str += f" H(w={heatmap.get('weight', 0.0):.2f})"
        
        if use_mean_points is not None:
            config_str += f" MP={'‚úì' if use_mean_points else '‚úó'}"
        
        print(config_str)
    
    def _print_final_results(self, results: dict):
        """Affiche les r√©sultats finaux de la recherche."""
        print(f"\nüèÜ R√âSULTATS FINAUX")
        print("=" * 40)
        
        # G√©rer les deux types de r√©sultats (random_search et coordinate_search)
        n_tests = results.get('n_samples_tested', results.get('n_evaluations', 0))
        print(f"√âvaluations: {n_tests}")
        print(f"Baseline: {results['baseline_score']:.2f}")
        print(f"Meilleur score: {results['best_score']:.2f}")
        print(f"Am√©lioration: {results['best_improvement']:+.2f}")
        
        if results['best_config']:
            print(f"\nüéØ Meilleure configuration:")
            best_use_mean_points = results.get('best_use_mean_points')
            self._print_config(results['best_config'], best_use_mean_points, "  ")
            
        # Top 5
        sorted_results = sorted(results['all_results'], key=lambda x: x['mean_distance'])
        print(f"\nüìà Top 5:")
        for i, result in enumerate(sorted_results[:5]):
            print(f"  {i+1}. {result['mean_distance']:.2f} "
                  f"({result['improvement']:+.2f}) - ", end="")
            use_mean_points = result.get('use_mean_points')
            self._print_config(result['config'], use_mean_points, "") 

if __name__ == "__main__":
    from src.utilities.worst_errors import select_frames_from_all_deciles

    frames_by_decile = select_frames_from_all_deciles(
        run_name="5_4", 
        n_frames_per_decile=10, 
        # video_id=4
    )

    fb = FilterConfigEvaluator(frames_by_decile, verbose=False)
    fb.load_data()
    # filter_config = {
    #     'norm': {'is_used': True, 'k': 150, 'x0': 13},
    #     'colinearity': {'is_used': True, 'k': 150, 'x0': 0.96},
    #     'heatmap': {
    #         'is_used': False, 
    #         'path': get_intermediate_dir() / 'heatmaps/unfiltered/global/global_heatmap.npy',
    #         'weight': 1.0
    #     }
    # }
    filter_config = {
        'norm': {'is_used': True, 'k': -10.0, 'x0': 1.0},
        'colinearity': {'is_used': True, 'k': 118.25, 'x0': 1.1053},
        'heatmap': {
            'is_used': True,    
            'path': get_intermediate_dir() / 'heatmaps/unfiltered/global/global_heatmap.npy',
            'weight': 0.79
        }
    }
    # Test de la nouvelle interface
    mean_distance = fb.evaluate_filter_config(filter_config=filter_config, use_mean_points=False)
    print(f"Distance moyenne: {mean_distance}")
    
    # Test avec les pr√©dictions
    # predictions = fb.predict_from_config(filter_config=filter_config, use_mean_points=True)
    # print(f"Pr√©dictions moyennes: {mx.mean(predictions)}")

    