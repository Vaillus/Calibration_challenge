"""
G√©n√©rateur de pr√©dictions √† partir de flux optiques avec filtrage.

Ce module g√©n√®re des pr√©dictions de points de fuite √† partir de flux optiques 
pr√©-calcul√©s. Il peut appliquer diff√©rents filtres et pond√©rations sur les flux 
avant l'estimation. Il fait partie du 4√®me arc du projet : filtrage des vecteurs.

Fonctionnalit√©s :
- G√©n√©ration de pr√©dictions par batch avec filtrage optionnel
- Support de multiples configurations de filtrage
- Traitement efficace des flux optiques pr√©-calcul√©s (.npz float16)
- Sauvegarde des pr√©dictions en format angles
- Gestion efficace de la m√©moire pour gros datasets

Auteur: Projet calib_challenge  
Derni√®re modification: 2024
"""

import time
import numpy as np
import mlx.core as mx
from pathlib import Path
from typing import Optional, Dict, Any, Tuple, List
import gc
import json

from src.utilities.paths import (
    get_flows_dir,
    get_pred_dir,
    ensure_dir_exists
)
from src.utilities.ground_truth import read_ground_truth_pixels, read_ground_truth_angles
from src.core.flow_filter import FlowFilterBatch
from src.utilities.pixel_angle_converter import pixels_to_angles
from src.core.optimizers import AdamOptimizer

# Camera parameters
FOCAL_LENGTH = 910


def optimize_batch_with_filtering(
    flow_batch: mx.array, 
    config: Optional[Dict[str, Any]] = None,
    plateau_threshold: float = 1e-4,
    plateau_patience: int = 3
) -> mx.array:
    """
    Optimise un batch de flux optiques avec filtrage optionnel.
    
    Args:
        flow_batch: Batch de flux optiques de shape (batch_size, h, w, 2)
        config: Configuration de filtrage. Si None, aucun filtrage appliqu√©.
                Structure:
                {
                    'filtering': {
                        'norm': {'is_used': bool, 'min_threshold': float},
                        'colinearity': {'is_used': bool, 'min_threshold': float}
                    },
                    'weighting': {
                        'norm': {'is_used': bool, 'type': str},
                        'colinearity': {'is_used': bool, 'type': str}
                    }
                }
        plateau_threshold: Seuil d'am√©lioration minimum pour continuer (d√©faut: 1e-4)
        plateau_patience: Nombre d'it√©rations pour v√©rifier am√©lioration (d√©faut: 3)
        
    Returns:
        Pr√©dictions des points de fuite de shape (batch_size, 2)
    """
    batch_size = flow_batch.shape[0]
    
    # V√©rifier si du filtrage est demand√©
    filtering_enabled = False
    if config is not None:
        filtering_enabled = (
            config.get('filtering', {}).get('norm', {}).get('is_used', False) or 
            config.get('filtering', {}).get('colinearity', {}).get('is_used', False) or
            config.get('weighting', {}).get('norm', {}).get('is_used', False) or
            config.get('weighting', {}).get('colinearity', {}).get('is_used', False)
        )
    
    if filtering_enabled:
        # Appliquer pipeline filtrage/pond√©ration
        flow_filter = FlowFilterBatch(config)
        filtered_flows, weights = flow_filter.filter_and_weight(flow_batch)
        
        mx.eval(filtered_flows)
        mx.eval(weights)
        
        # Utiliser flux filtr√©s pour optimisation
        flows_to_optimize = filtered_flows
    else:
        # Pas de filtrage - utiliser flux originaux directement
        flows_to_optimize = flow_batch
    
    # Optimiser avec l'optimiseur Adam
    predictions = AdamOptimizer(plateau_threshold=plateau_threshold, plateau_patience=plateau_patience).optimize_batch(flows_to_optimize)
    mx.eval(predictions)
    
    return predictions


class FlowPredictor:
    """
    Classe principale pour la g√©n√©ration de pr√©dictions √† partir de flux optiques.
    
    G√®re le traitement complet d'une ou plusieurs vid√©os avec diff√©rentes
    configurations de filtrage et sauvegarde les pr√©dictions r√©sultantes.
    """
    
    def __init__(self):
        """Initialise le g√©n√©rateur de pr√©dictions avec les chemins du projet."""
        self.flows_dir = get_flows_dir()
        self.pred_base_dir = get_pred_dir()
        
    def process_video(
        self, 
        video_index: int, 
        config: Optional[Dict[str, Any]] = None,
        run_name: str = "default",
        batch_size: int = 200
    ) -> bool:
        """
        Traite une vid√©o compl√®te avec la configuration donn√©e.
        
        Args:
            video_index: Index de la vid√©o (0-4)
            config: Configuration de filtrage (None = pas de filtrage)
            run_name: Nom du run d'exp√©rimentation
            batch_size: Taille des batches pour traitement
            
        Returns:
            True si succ√®s, False sinon
        """
        print(f"\nüé¨ Traitement vid√©o {video_index} - Run: {run_name}")
        
        # V√©rification existence fichier flux
        npz_path = self.flows_dir / f"{video_index}_float16.npz"
        if not npz_path.exists():
            print(f"‚ùå Fichier flux non trouv√©: {npz_path}")
            return False
        
        # Pr√©paration dossier sortie
        pred_run_dir = ensure_dir_exists(self.pred_base_dir / run_name)
        output_file = pred_run_dir / f"{video_index}.txt"
        
        # Sauvegarde configuration
        config_file = pred_run_dir / "config.json"
        self._save_config(config_file, config, run_name)
        
        try:
            # Chargement flux (float16 -> float32)
            print(f"üìÇ Chargement flux depuis: {npz_path}")
            with np.load(npz_path) as data:
                flows_data_f16 = mx.array(data['flow'])
            mx.eval(flows_data_f16)
            
            flows_data = flows_data_f16.astype(mx.float32)
            mx.eval(flows_data)
            del flows_data_f16
            gc.collect()
            
            total_frames = flows_data.shape[0]
            print(f"üìä Total frames: {total_frames}")
            
            # Chargement ground truth pour conversion angles
            _, image_width, image_height = read_ground_truth_angles(video_index)
            
            # Traitement par batches
            all_predictions = []
            total_time = 0
            
            print(f"üîÑ Traitement par batches de {batch_size}...")
            if config is None:
                print("‚öôÔ∏è  Mode: AUCUN FILTRAGE")
            else:
                print("‚öôÔ∏è  Mode: FILTRAGE ACTIV√â")
            
            for start_idx in range(0, total_frames, batch_size):
                end_idx = min(start_idx + batch_size, total_frames)
                
                # Extraction batch
                flow_batch = flows_data[start_idx:end_idx]
                mx.eval(flow_batch)
                
                # Optimisation avec/sans filtrage
                start_time = time.time()
                predictions = optimize_batch_with_filtering(flow_batch, config)
                mx.eval(predictions)
                batch_time = time.time() - start_time
                total_time += batch_time
                
                all_predictions.extend(predictions)
                
                print(f"  Frames {start_idx:4d}-{end_idx-1:4d}: {batch_time:.2f}s")
                
                # Nettoyage m√©moire
                del flow_batch, predictions
                gc.collect()
                
                # Nettoyage p√©riodique
                if (start_idx // batch_size) % 10 == 9:
                    print(f"    üßπ Nettoyage m√©moire batch {start_idx // batch_size + 1}")
                    if all_predictions:
                        temp_pred = mx.stack(all_predictions, axis=0)
                        mx.eval(temp_pred)
                        all_predictions = list(temp_pred)
                        del temp_pred
                    gc.collect()
            
            # Finalisation pr√©dictions
            all_predictions = mx.stack(all_predictions, axis=0)
            mx.eval(all_predictions)
            predictions_np = np.array(all_predictions)
            
            # Correction offset temporel (duplication premi√®re frame)
            first_prediction = predictions_np[0:1]
            corrected_predictions_pixels = np.vstack([first_prediction, predictions_np])
            
            # Conversion pixels -> angles
            corrected_predictions_angles = []
            for x, y in corrected_predictions_pixels:
                yaw, pitch = pixels_to_angles(x, y, FOCAL_LENGTH, image_width, image_height)
                corrected_predictions_angles.append([yaw, pitch])
            corrected_predictions_angles = np.array(corrected_predictions_angles)
            
            # Sauvegarde r√©sultats
            np.savetxt(output_file, corrected_predictions_angles, fmt='%.15e')
            
            # Statistiques
            fps = total_frames / total_time
            print(f"\n‚úÖ Vid√©o {video_index} termin√©e:")
            print(f"   ‚è±Ô∏è  Temps total: {total_time:.2f}s")
            print(f"   üöÄ FPS: {fps:.2f}")
            print(f"   üíæ Pr√©dictions: {output_file}")
            print(f"   üìè Frames corrig√©es: {len(corrected_predictions_angles)}")
            
            # Nettoyage final
            del flows_data, all_predictions
            gc.collect()
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur traitement vid√©o {video_index}: {e}")
            return False
    
    def process_multiple_videos(
        self,
        video_indices: Optional[List[int]] = None,
        config: Optional[Dict[str, Any]] = None,
        run_name: str = "default"
    ) -> None:
        """
        Traite plusieurs vid√©os avec la m√™me configuration.
        
        Args:
            video_indices: Liste des indices √† traiter (d√©faut: toutes 0-4)
            config: Configuration de filtrage
            run_name: Nom du run d'exp√©rimentation
        """
        if video_indices is None:
            video_indices = list(range(5))  # Toutes les vid√©os
        
        print(f"üöÄ D√âMARRAGE RUN: {run_name}")
        print(f"üìÇ Flux source: {self.flows_dir}")
        print(f"üìÇ Pr√©dictions: {self.pred_base_dir / run_name}")
        print(f"üéØ Vid√©os: {video_indices}")
        
        success_count = 0
        for video_idx in video_indices:
            if self.process_video(video_idx, config, run_name):
                success_count += 1
        
        print(f"\nüèÅ RUN '{run_name}' TERMIN√â: {success_count}/{len(video_indices)} vid√©os r√©ussies")
    
    def _save_config(self, config_file: Path, config: Optional[Dict[str, Any]], run_name: str) -> None:
        """Sauvegarde la configuration du run."""
        config_to_save = {
            "run_name": run_name,
            "config": config,
            "description": "Aucun filtrage appliqu√©" if config is None else "Filtrage appliqu√©",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        with open(config_file, 'w') as f:
            json.dump(config_to_save, f, indent=2)


def main(
    video_indices: Optional[List[int]] = None,
    config: Optional[Dict[str, Any]] = None,
    run_name: str = "default"
) -> None:
    """
    Point d'entr√©e principal pour la g√©n√©ration de pr√©dictions √† partir de flux.
    
    Args:
        video_indices: Vid√©os √† traiter (d√©faut: toutes)
        config: Configuration de filtrage (d√©faut: aucun filtrage)
        run_name: Nom du run pour organisation des r√©sultats
    """
    predictor = FlowPredictor()
    predictor.process_multiple_videos(video_indices, config, run_name)


if __name__ == "__main__":
    # Exemple d'utilisation sans filtrage
    main(video_indices=[1, 2, 3, 4], config=None, run_name="no_filtering") 