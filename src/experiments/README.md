# ğŸ§ª Dossier Experiments

Ce dossier contient tous les scripts d'expÃ©rimentation, de benchmark et d'analyse du projet.

## ğŸ“ Organisation

### Benchmarks d'optimisation
- **`benchmark_adam_plateau.py`** : Test des paramÃ¨tres d'early stopping pour Adam
- **`benchmark_lbfgs_vs_adam.py`** : Comparaison des deux mÃ©thodes d'optimisation (Ã  dÃ©placer)

### Benchmarks de filtrage
- **`filter_benchmark.py`** : Tests exhaustifs des paramÃ¨tres de filtrage (Ã  dÃ©placer)

### Analyses de donnÃ©es
- **`norm_distribution_by_video.py`** : Analyse des distributions de normes par vidÃ©o (Ã  dÃ©placer)
- **`colinearity_by_norm_analysis.py`** : Analyse de la relation colinÃ©aritÃ©/norme (Ã  dÃ©placer)
- **`flow_norm_analysis.py`** : Analyse approfondie des normes de flux optique (Ã  dÃ©placer)

### Visualisations
- **`visualize_error.py`** : Visualisation des erreurs de prÃ©diction (Ã  dÃ©placer)
- **`visualize_distances.py`** : Visualisation des distributions de distances (Ã  dÃ©placer)
- **`visualize_flow.py`** : Visualisation des champs de flux optique (Ã  dÃ©placer)

## ğŸ¯ Usage

### Lancer un benchmark Adam
```python
from src.experiments.benchmark_adam_plateau import benchmark_plateau_detection

# Test rapide
results = benchmark_plateau_detection(max_frames=10, video_id=0)

# Test complet
results = benchmark_plateau_detection(max_frames=100, video_id=2)
```

### Lancer en command line
```bash
cd calib_challenge/src/experiments
python benchmark_adam_plateau.py
```

## ğŸ“‹ Ã€ faire

- [ ] DÃ©placer tous les scripts de benchmark depuis `src/` vers `experiments/`
- [ ] Standardiser les formats de sortie des benchmarks
- [ ] CrÃ©er un script master qui lance tous les benchmarks
- [ ] Ajouter des tests de rÃ©gression pour les expÃ©riences importantes 