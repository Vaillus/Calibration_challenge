"""
G√©n√©rateur de pr√©dictions √† partir de flux optiques avec filtrage.

Ce module g√©n√®re des pr√©dictions de points de fuite √† partir de flux optiques 
pr√©-calcul√©s. Il peut appliquer diff√©rents filtres et pond√©rations sur les flux 
avant l'estimation. Il fait partie du 4√®me arc du projet : filtrage des vecteurs.

Fonctionnalit√©s :
- G√©n√©ration de pr√©dictions par batch avec filtrage optionnel
- Support de multiples configurations de filtrage
- Traitement efficace des flux optiques pr√©-calcul√©s (.npz float16)
- Sauvegarde des pr√©dictions en format angles
- Gestion efficace de la m√©moire pour gros datasets

Auteur: Projet calib_challenge  
Derni√®re modification: 2024
"""

import time
import numpy as np
import mlx.core as mx
from pathlib import Path
from typing import Optional, Dict, Any, Tuple, List
import gc
import json

from src.utilities.paths import (
    get_flows_dir,
    get_pred_dir,
    ensure_dir_exists
)
from src.utilities.ground_truth import read_ground_truth_pixels, read_ground_truth_angles
from src.core.flow_filter import FlowFilterBatch
from src.utilities.pixel_angle_converter import pixels_to_angles
from src.core.optimizers import AdamOptimizer
from src.utilities.project_constants import get_project_constants
from src.utilities.load_flows import load_flows



def optimize_batch_with_filtering(
    flow_batch: mx.array, 
    config: Optional[Dict[str, Any]] = None
) -> mx.array:
    """
    Optimise un batch de flux optiques avec filtrage optionnel.
    
    Args:
        flow_batch: Batch de flux optiques de shape (batch_size, h, w, 2)
        config: Configuration de filtrage. Si None, aucun filtrage appliqu√©.
                Structure:
                {
                    'filtering': {
                        'norm': {'is_used': bool, 'min_threshold': float},
                        'colinearity': {'is_used': bool, 'min_threshold': float}
                    },
                    'weighting': {
                        'norm': {'is_used': bool, 'type': str},
                        'colinearity': {'is_used': bool, 'type': str}
                    }
                }
        plateau_threshold: Seuil d'am√©lioration minimum pour continuer (d√©faut: 1e-4)
        plateau_patience: Nombre d'it√©rations pour v√©rifier am√©lioration (d√©faut: 3)
        
    Returns:
        Pr√©dictions des points de fuite de shape (batch_size, 2)
    """
    
    # V√©rifier si du filtrage est demand√©
    filtering_enabled = False
    if config is not None:
        filtering_enabled = (
            config.get('norm', {}).get('is_used', False) or 
            config.get('colinearity', {}).get('is_used', False) or
            config.get('heatmap', {}).get('is_used', False)
        )
    
    if filtering_enabled:
        # Appliquer pipeline filtrage/pond√©ration
        flow_filter = FlowFilterBatch(config)
        flow_batch, weights_batch = flow_filter.filter_and_weight(flow_batch)
        
        mx.eval(flow_batch)
        mx.eval(weights_batch)
    
    # Optimiser avec l'optimiseur Adam
    predictions = AdamOptimizer().optimize_batch(
        flow_batch, 
        weights_batch=weights_batch
    )
    mx.eval(predictions)
    
    return predictions


class FlowPredictor:
    """
    Classe principale pour la g√©n√©ration de pr√©dictions √† partir de flux optiques.
    
    G√®re le traitement complet d'une ou plusieurs vid√©os avec diff√©rentes
    configurations de filtrage et sauvegarde les pr√©dictions r√©sultantes.
    """
    
    def __init__(self):
        pass

    def process_video(
        self, 
        video_index: int, 
        config: Optional[Dict[str, Any]] = None,
        run_name: str = "default",
        batch_size: int = 200
    ) -> bool:
        """
        Traite une vid√©o compl√®te avec la configuration donn√©e.
        
        Args:
            video_index: Index de la vid√©o (0-4)
            config: Configuration de filtrage (None = pas de filtrage)
            run_name: Nom du run d'exp√©rimentation
            batch_size: Taille des batches pour traitement
            
        Returns:
            True si succ√®s, False sinon
        """
        print(f"\nüé¨ Traitement vid√©o {video_index} - Run: {run_name}")
        
        # Pr√©paration
        pred_run_dir = self._prepare_output_directories(run_name, config)
        
        # Chargement des donn√©es
        flows_data = self._load_video_flows(video_index)
        if flows_data is None:
            return False
        
        total_frames = flows_data.shape[0]
        
        # Traitement principal
        all_predictions, total_time = self._process_batches(
            flows_data, config, batch_size
        )
        
        # Post-traitement
        predictions_angles = self._post_process_predictions(all_predictions)
        
        # Sauvegarde et statistiques
        self._save_results_and_print_stats(
            predictions_angles, pred_run_dir, video_index, total_time, total_frames
        )
        
        # Nettoyage final
        del flows_data, all_predictions
        gc.collect()
        
        return True
    
    def _prepare_output_directories(
        self, 
        run_name: str, 
        config: Optional[Dict[str, Any]]
    ) -> Path:
        """Pr√©pare les dossiers de sortie et sauvegarde la configuration."""
        pred_run_dir = ensure_dir_exists(get_pred_dir(run_name))
        config_file = pred_run_dir / "config.json"
        self._save_config(config_file, config, run_name)
        return pred_run_dir
    
    def _load_video_flows(self, video_index: int) -> Optional[mx.array]:
        """Charge les flux optiques d'une vid√©o."""
        try:
            flows_data = load_flows(video_index, return_mlx=True)
            mx.eval(flows_data)
            print(f"üìä Total frames: {flows_data.shape[0]}")
            return flows_data
        except Exception as e:
            print(f"‚ùå Erreur chargement flux vid√©o {video_index}: {e}")
            return None
    
    def _process_batches(
        self, 
        flows_data: mx.array, 
        config: Optional[Dict[str, Any]], 
        batch_size: int
    ) -> Tuple[List[mx.array], float]:
        """Traite les flux par batches et retourne les pr√©dictions et le temps total."""
        total_frames = flows_data.shape[0]
        all_predictions = []
        total_time = 0
        
        print(f"üîÑ Traitement par batches de {batch_size}...")
        if config is None:
            print("‚öôÔ∏è  Mode: AUCUN FILTRAGE")
        else:
            print("‚öôÔ∏è  Mode: FILTRAGE ACTIV√â")
        
        for start_idx in range(0, total_frames, batch_size):
            end_idx = min(start_idx + batch_size, total_frames)
            
            # Extraction batch
            flow_batch = flows_data[start_idx:end_idx]
            mx.eval(flow_batch)
            
            # Optimisation avec/sans filtrage
            start_time = time.time()
            predictions = optimize_batch_with_filtering(flow_batch, config)
            mx.eval(predictions)
            batch_time = time.time() - start_time
            total_time += batch_time
            
            all_predictions.extend(predictions)
            
            print(f"  Frames {start_idx:4d}-{end_idx-1:4d}: {batch_time:.2f}s")
            
            # Nettoyage m√©moire
            del flow_batch, predictions
            gc.collect()
            
            # Nettoyage p√©riodique
            if (start_idx // batch_size) % 10 == 9:
                print(f"    üßπ Nettoyage m√©moire batch {start_idx // batch_size + 1}")
                if all_predictions:
                    temp_pred = mx.stack(all_predictions, axis=0)
                    mx.eval(temp_pred)
                    all_predictions = list(temp_pred)
                    del temp_pred
                gc.collect()
        
        return all_predictions, total_time
    
    def _post_process_predictions(self, all_predictions: List[mx.array]) -> np.array:
        """Post-traite les pr√©dictions : stack, correction offset, conversion angles."""
        # Finalisation pr√©dictions
        all_predictions = mx.stack(all_predictions, axis=0)
        mx.eval(all_predictions)
        predictions_np = np.array(all_predictions)
        
        # Correction offset temporel (duplication premi√®re frame)
        first_prediction = predictions_np[0:1]
        corrected_predictions_pixels = np.vstack([first_prediction, predictions_np])
        
        # Conversion pixels -> angles
        corrected_predictions_angles = []
        for x, y in corrected_predictions_pixels:
            yaw, pitch = pixels_to_angles(x, y)
            corrected_predictions_angles.append([yaw, pitch])
        
        return np.array(corrected_predictions_angles)
    
    def _save_results_and_print_stats(
        self, 
        predictions_angles: np.array, 
        pred_run_dir: Path, 
        video_index: int, 
        total_time: float, 
        total_frames: int
    ) -> None:
        """Sauvegarde les r√©sultats et affiche les statistiques."""
        output_file = pred_run_dir / f"{video_index}.txt"
        np.savetxt(output_file, predictions_angles, fmt='%.15e')
        
        # Statistiques
        fps = total_frames / total_time
        print(f"\n‚úÖ Vid√©o {video_index} termin√©e:")
        print(f"   ‚è±Ô∏è  Temps total: {total_time:.2f}s")
        print(f"   üöÄ FPS: {fps:.2f}")
        print(f"   üíæ Pr√©dictions: {output_file}")
        print(f"   üìè Frames corrig√©es: {len(predictions_angles)}")
        


    def process_multiple_videos(
        self,
        video_indices: Optional[List[int]] = None,
        config: Optional[Dict[str, Any]] = None,
        run_name: str = "default"
    ) -> None:
        """
        Traite plusieurs vid√©os avec la m√™me configuration.
        
        Args:
            video_indices: Liste des indices √† traiter (d√©faut: toutes 0-4)
            config: Configuration de filtrage
            run_name: Nom du run d'exp√©rimentation
        """
        if video_indices is None:
            video_indices = list(range(5))  # Toutes les vid√©os
        
        print(f"üöÄ D√âMARRAGE RUN: {run_name}")
        print(f"üìÇ Flux source: {get_flows_dir()}")
        print(f"üìÇ Pr√©dictions: {get_pred_dir(run_name)}")
        print(f"üéØ Vid√©os: {video_indices}")
        
        success_count = 0
        for video_idx in video_indices:
            if self.process_video(video_idx, config, run_name):
                success_count += 1
        
        print(f"\nüèÅ RUN '{run_name}' TERMIN√â: {success_count}/{len(video_indices)} vid√©os r√©ussies")
    
    def _save_config(self, config_file: Path, config: Optional[Dict[str, Any]], run_name: str) -> None:
        """Sauvegarde la configuration du run."""
        config_to_save = {
            "run_name": run_name,
            "config": config,
            "description": "Aucun filtrage appliqu√©" if config is None else "Filtrage appliqu√©",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        with open(config_file, 'w') as f:
            json.dump(config_to_save, f, indent=2)


def main(
    video_indices: Optional[List[int]] = None,
    config: Optional[Dict[str, Any]] = None,
    run_name: str = "default"
) -> None:
    """
    Point d'entr√©e principal pour la g√©n√©ration de pr√©dictions √† partir de flux.
    
    Args:
        video_indices: Vid√©os √† traiter (d√©faut: toutes)
        config: Configuration de filtrage (d√©faut: aucun filtrage)
        run_name: Nom du run pour organisation des r√©sultats
    """
    predictor = FlowPredictor()
    predictor.process_multiple_videos(video_indices, config, run_name)


if __name__ == "__main__":
    config = {
        'norm': {'is_used': True, 'k': 150, 'x0': 13},
        'colinearity': {'is_used': True, 'k': 150, 'x0': 0.96},
        'heatmap': {'is_used': False, 'weight': 0.0}
    }
    # Exemple d'utilisation sans filtrage
    main(config=config, run_name="5") 