"""
Script de pr√©diction de points de fuite √† partir de vid√©os de conduite.

Utilise l'analyse de flux optique avec segmentation v√©hicule optionnelle.
Deux m√©thodes disponibles : 'flow' (s√©paration directe) et 'colinearity' (optimisation).


Configuration via config.json dans le m√™me dossier.
"""

import cv2
import numpy as np
import os
import json
import mlx.core as mx
from typing import Optional, Dict, Any, List
from pathlib import Path
import gc
import time

from src.core.flow import calculate_flow, find_separation_points
from src.utilities.pixel_angle_converter import pixels_to_angles
from src.core.segmentation import VehicleDetector
from src.core.optimizers import AdamOptimizer
from src.utilities.paths import get_labeled_dir, get_pred_dir, get_masks_dir, ensure_dir_exists
from src.utilities.project_constants import get_project_constants
from src.utilities.fix_predictions import fix_predictions
from src.core.flow_filter import FlowFilterSample


def load_config(config_path: Optional[str] = None) -> Dict[str, Any]:
    """Charge la configuration depuis config.json."""
    if config_path is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        config_path = os.path.join(script_dir, 'config.json')
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    return {
        'prediction_method': config.get('prediction_method', 'colinearity'),
        'use_segmentation': config.get('use_segmentation', True),
        'filter_config': config.get('filter_config', None),
        'optimizer_config': config.get('optimizer_config', None)
    }


class VideoProcessor:
    """
    Processeur vid√©o pour pr√©diction de points de fuite.
    
    G√®re le traitement complet d'une vid√©o avec flux optique,
    segmentation v√©hicule optionnelle et estimation du point de fuite.
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.detector = None
        self.manual_mask = None
        self.prev_vehicle_mask = None
        self.prev_gray = None
        self.frame_count = 0
        self.total_frames = 0
        self.results = []
        
        # Initialisation filtre et optimiseur avec configs
        filter_config = config.get('filter_config')
        if filter_config:
            self.filter = FlowFilterSample(filter_config)
        else:
            self.filter = FlowFilterSample()  # Utilise config par d√©faut
        
        optimizer_config = config.get('optimizer_config')
        if optimizer_config:
            self.optimizer = AdamOptimizer(**optimizer_config)
        else:
            self.optimizer = AdamOptimizer()  # Utilise config par d√©faut

    def process_video(
        self, 
        video_index: int,
        run_name: str = "default"
    ) -> bool:
        """
        Traite une vid√©o compl√®te et sauvegarde les pr√©dictions.
        
        Args:
            video_index: Index de la vid√©o 
            run_name: Nom du run d'exp√©rimentation
            
        Returns:
            True si succ√®s, False sinon
        """
        # Create video path
        video_path = get_labeled_dir() / f"{video_index}.hevc"
        if not os.path.exists(video_path):
            print(f"‚ö†Ô∏è  Vid√©o {video_index} introuvable")
            return False

        # Pr√©paration dossiers de sortie
        pred_run_dir = self._prepare_output_directories(run_name)
        
        # Initialisation
        cap = self._initialize_video(str(video_path))
        if cap is None:
            return False
        
        self._setup_processing_components(str(video_path))
        
        # Premi√®re frame
        first_frame = self._process_first_frame(cap)
        if first_frame is None:
            cap.release()
            return False
        
        # Traitement de toutes les frames
        self._process_all_frames(cap)
        
        # Nettoyage
        cap.release()
        gc.collect()
        
        # Sauvegarde pr√©dictions
        self._save_predictions(pred_run_dir, video_index)
        
        print(f"\n‚úÖ Vid√©o {video_index} termin√©e: {len(self.results)} frames")
        return True

    def _prepare_output_directories(self, run_name: str) -> Path:
        """Pr√©pare les dossiers de sortie et sauvegarde la configuration."""
        pred_run_dir = ensure_dir_exists(get_pred_dir(run_name))
        
        # Sauvegarde configuration
        config_file = pred_run_dir / "config.json"
        self._save_config(config_file, run_name)
        
        return pred_run_dir

    def _save_config(self, config_file: Path, run_name: str) -> None:
        """Sauvegarde la configuration du run."""
        config_to_save = {
            "run_name": run_name,
            "config": self.config,
            "description": f"Make predictions - m√©thode {self.config['prediction_method']}",
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        with open(config_file, 'w') as f:
            json.dump(config_to_save, f, indent=2)

    def _save_predictions(self, pred_run_dir: Path, video_index: int) -> None:
        """Sauvegarde les pr√©dictions dans le dossier du run."""
        output_file = pred_run_dir / f"{video_index}.txt"
        
        with open(output_file, 'w') as f:
            for yaw, pitch in self.results:
                f.write(f"{yaw:.6f} {pitch:.6f}\n")
        
        print(f"üíæ Pr√©dictions: {output_file}")

    def _initialize_video(self, video_path: str) -> Optional[cv2.VideoCapture]:
        """Initialise la capture vid√©o et compte les frames."""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print("‚ùå Impossible d'ouvrir la vid√©o")
            return None
        
        self.total_frames, cap = self._get_video_frame_count(cap, video_path)
        return cap
    
    def _get_video_frame_count(self, cap: cv2.VideoCapture, video_path: str) -> tuple:
        """Compte le nombre r√©el de frames dans la vid√©o."""
        current_pos = cap.get(cv2.CAP_PROP_POS_FRAMES)
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        
        frame_count = 0
        max_frames = 2000
        while frame_count < max_frames:
            ret, _ = cap.read()
            if not ret:
                break
            frame_count += 1
        
        print(f"üìä Total frames: {frame_count}")
        
        cap.release()
        cap = cv2.VideoCapture(video_path)
        cap.set(cv2.CAP_PROP_POS_FRAMES, current_pos)
        
        return frame_count, cap

    def _setup_processing_components(self, video_path: str) -> None:
        """Configure les composants de traitement."""
        frame_width = get_project_constants()["frame_width"]
        frame_height = get_project_constants()["frame_height"]
        
        # Initialisation segmentation si activ√©e
        if self.config['use_segmentation']:
            self.detector = VehicleDetector()
            self.manual_mask = np.zeros((frame_height, frame_width), dtype=np.uint8)
            self.prev_vehicle_mask = np.zeros((frame_height, frame_width), dtype=np.uint8)
            
            # Chargement masque manuel
            self._load_manual_mask(video_path)

    def _load_manual_mask(self, video_path: str) -> None:
        """Charge le masque manuel si disponible."""
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        mask_path = get_masks_dir() / f"{video_name}_mask.png"
        
        if os.path.exists(mask_path):
            print(f"üìÇ Masque charg√©: {mask_path}")
            self.manual_mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)
        else:
            print("üìÇ Pas de masque manuel trouv√©")

    def _process_first_frame(self, cap: cv2.VideoCapture) -> Optional[np.ndarray]:
        """Traite la premi√®re frame et initialise prev_gray."""
        ret, frame = cap.read()
        if not ret:
            print("‚ùå Impossible de lire la premi√®re frame")
            return None
        
        self.prev_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        return frame

    def _process_all_frames(self, cap: cv2.VideoCapture) -> None:
        """Traite toutes les frames de la vid√©o."""
        while True:
            # Affichage progression
            progress = (self.frame_count / (self.total_frames - 1)) * 100
            print(f"\rProgression: {progress:.1f}%", end="", flush=True)
            
            ret, frame = cap.read()
            if not ret:
                break
            
            self.frame_count += 1
            self._process_single_frame(frame)

    def _process_single_frame(self, frame: np.ndarray) -> None:
        """Traite une frame individuelle."""
        # Conversion grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        # Gestion masques
        combined_mask = self._create_mask(frame)
        # Calcul flux optique et filtrage
        flow, _, _ = calculate_flow(self.prev_gray, gray, combined_mask)
        flow, weights = self.filter.filter_and_weight(flow)
        
        # Pr√©diction selon m√©thode choisie
        x, y = self._predict_vanishing_point(flow, combined_mask, weights)
        
        # Conversion angles et stockage
        yaw, pitch = pixels_to_angles(x, y)
        self._store_result(x, y, yaw, pitch)
        
        # Mise √† jour √©tat
        self.prev_gray = gray

    def _create_mask(self, frame: np.ndarray) -> np.ndarray:
        """d√©tecte les v√©hicules sur la frame, cr√©e le masque correspondant 
        dilate le masque 
        combine avec le masque du capot et le masque de la frame pr√©c√©dente.
        """
        if not self.config['use_segmentation']:
            return np.zeros_like(self.prev_gray)
        
        current_vehicle_mask = self.detector.detect_vehicles(frame)
        current_vehicle_mask = self.detector.dilate_mask(current_vehicle_mask)
        combined_mask = self.detector.combine_masks(
            self.manual_mask, 
            current_vehicle_mask, 
            self.prev_vehicle_mask
        )
        self.prev_vehicle_mask = current_vehicle_mask
        return combined_mask

    def _predict_vanishing_point(self, flow: np.ndarray, mask: np.ndarray, weights: np.ndarray) -> tuple:
        """Pr√©dit le point de fuite selon la m√©thode configur√©e."""
        if self.config['prediction_method'] == "flow":
            return find_separation_points(flow, mask)
        elif self.config['prediction_method'] == "colinearity":
            vanishing_point = self.optimizer.optimize_single(flow, weights=weights)
            return map(int, vanishing_point) # cleaner than converting to int element by element
        else:
            raise ValueError(f"M√©thode inconnue: {self.config['prediction_method']}")

    def _store_result(self, x: int, y: int, yaw: float, pitch: float) -> None:
        """Stocke le r√©sultat de pr√©diction."""
        self.results.append([yaw, pitch])



def main(
    video_indices: Optional[List[int]] = None,
    run_name: str = "default"
) -> None:
    """
    Traite les vid√©os pour pr√©diction de points de fuite.
    
    Args:
        video_indices: Indices des vid√©os √† traiter (d√©faut: toutes)
        run_name: Nom du run d'exp√©rimentation
    """
    if video_indices is None:
        video_indices = list(range(5))

    # Configuration
    config = load_config()
    
    print(f"üöÄ D√âMARRAGE RUN: {run_name}")
    print(f"üìÇ Pr√©dictions: {get_pred_dir(run_name)}")
    print(f"üéØ Vid√©os: {video_indices}")
    print(f"‚öôÔ∏è  M√©thode: {config['prediction_method']}")
    
    # Traitement vid√©os
    success_count = 0
    for video_index in video_indices:
        print(f"\nüé¨ Traitement vid√©o {video_index} - Run: {run_name}")
        # Traitement
        processor = VideoProcessor(config)
        success = processor.process_video(video_index, run_name)
        if success:
            success_count += 1

    print(f"\nüèÅ RUN '{run_name}' TERMIN√â: {success_count}/{len(video_indices)} vid√©os r√©ussies")


if __name__ == "__main__":
    main() 